\section{Prior Work}

Mobilyze! \cite{Burns2011} is the first system we know of that  is designed to explore the use of passively collected mobile phone data in order to precisely deploy remote behavioral interventions related to depression.  Eight participants were recruited to try a smartphone application, Mobilyze!, which passively recorded 38 different types of data including location, motion, time, phone orientation, and current application. Mobilyze also notified the participants about 5 times per day of an in-app survey to fill out.  This survey asked questions like “How much physical activity are you engaging in?”, “What is your location?”, “What are you conversing about?”, and perhaps most importantly “What is your current mood?”.  While the project showed an interesting way of passively collecting sensor data and actively collecting the appropriate labels for this data from the participant, the results of the machine learning task were not as encouraging as they could only predict mood at about rate of pure chance. Another conern is that participants were not using their own phones.  This potentially resulted in participants using the phones unnaturally, and could have had a large effect on the EMA survey adherence rate.  Additionally, basic machine learning methods were used without tuning to determine the feasibility of such an intervention system as opposed to ensemble methods or tuning methods like grid search which have been known to improve performance when little data is available.  Our study recruited participants who were already engaged in some kind of self-tracking (and thus used their own phone for similar tasks) and the machine learning methods being used are comprehensive while still recognizing feasibility in a real world deployment.

The StudentLife study presents a large scale passive data collection study deployed to test the feasibility of predicting academic outcomes and mental health throughout a standard college semester\cite{Wang}.  Similar to Burns et al. this study uses a suite of passively collected sensor data labeled with periodically collected in-app survey data that provides the labeling necessary for evaluation of the system.  The results are ultimately much more promising than those reported in Burn et al., but this is perhaps due to the additional attention paid to design and scale during the data collection stage and the focus on correlations instead of predictions in the analysis stage.  These two features keep the paper well scoped and very informative for those interested in context sensing.